{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup : Installing Libraries"
      ],
      "metadata": {
        "id": "QqrVERQ4Kjq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9YUEs-pKMYm"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install langchain openai\n",
        "!pip install --user \"langchain-community==0.2.10\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "N-V-TQjx_h6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "id": "lcK58OjU_9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "NRW3z6GjK__W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import CSVLoader"
      ],
      "metadata": {
        "id": "JI4wNay9LE5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSV Loader"
      ],
      "metadata": {
        "id": "8bvPb4jlLQ8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath =\"/content/amazon_electronics_clean.csv\""
      ],
      "metadata": {
        "id": "pJHqa7CWLcr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path=filepath, encoding=\"utf-8\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "7plMI8xkLUXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in data[:2]:\n",
        "    print(d.page_content)\n"
      ],
      "metadata": {
        "id": "TSqYIaf2y5dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parse Each Document\n",
        "\n",
        "Data list contains Document objects.\n",
        "Each document’s page_content is a long text block with lines like key: value\n",
        "\n",
        "We’ll split and map those lines into a dictionary."
      ],
      "metadata": {
        "id": "hWZ4Jl34zilb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_products_info(doc):\n",
        "  lines = doc.page_content.split(\"\\n\")\n",
        "  product_data={}\n",
        "  for line in lines:\n",
        "    if \": \" in line:\n",
        "      key, value = line.split(\": \",1)\n",
        "      product_data[key.strip()] = value.strip()\n",
        "  return product_data"
      ],
      "metadata": {
        "id": "DFYS3S7KzllB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Relevant Fields"
      ],
      "metadata": {
        "id": "6cdiiZtF0Zes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Field\tWhy it matters\n",
        "\n",
        "product_title\tDescribes the item type (important for similarity).\n",
        "\n",
        "description\tGives functional and design details (semantic meaning).\n",
        "\n",
        "main_category\tHelps narrow down similar product groups.\n",
        "\n",
        "brand\tBrand reputation often affects performance.\n",
        "\n",
        "price\tNumeric comparison for performance insights.\n",
        "\n",
        "average_rating\tBase measure for predicting performance.\n",
        "\n",
        "text\tProvides real customer sentiment and experience.\n",
        "\n",
        "review_title\tAdds summary sentiment.\n",
        "\n",
        "\n",
        "##Optional columns:\n",
        "\n",
        "details\tUse selectively (e.g., “Material”, “Connectivity”). Good for technical matching.\n",
        "\n",
        "rating_number\tTo weigh popularity (can help in numeric modeling later).\n",
        "\n",
        "verified_purchase\tCan improve credibility weighting.\n",
        "\n",
        "##Drop for now\n",
        "parent_asin\tJust an ID, no semantic meaning.\n",
        "\n",
        "store\tOften same as brand.\n",
        "\n",
        "brand_consolidated\tDuplicate field."
      ],
      "metadata": {
        "id": "YNnH6FNt1BxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relevant_fields(product_data):\n",
        "  keys_to_keep = [\n",
        "      \"product_title\",\n",
        "        \"brand\",\n",
        "        \"main_category\",\n",
        "        \"price\",\n",
        "        \"description\",\n",
        "        \"average_rating\",\n",
        "        \"review_title\",\n",
        "        \"text\"\n",
        "  ]\n",
        "  return {k: product_data.get(k, \"\") for k in keys_to_keep}"
      ],
      "metadata": {
        "id": "TVmz66sS0cUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Format for Embedding"
      ],
      "metadata": {
        "id": "TsNs31Y91kMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_for_embedding(product_data):\n",
        "    return f\"\"\"\n",
        "    Product Title: {product_data.get('product_title', '')}\n",
        "    Brand: {product_data.get('brand', '')}\n",
        "    Category: {product_data.get('main_category', '')}\n",
        "    Price: {product_data.get('price', '')}\n",
        "    Description: {product_data.get('description', '')}\n",
        "    Average Rating: {product_data.get('average_rating', '')}\n",
        "    Review Title: {product_data.get('review_title', '')}\n",
        "    Review: {product_data.get('text', '')}\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "9Ln_R-ia1NCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing all the documents"
      ],
      "metadata": {
        "id": "a3K11uCT1tNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "cleaned_documents = []\n",
        "for doc in data:\n",
        "    product_data = parse_products_info(doc)\n",
        "    relevant_data = extract_relevant_fields(product_data)\n",
        "    formatted_text = format_for_embedding(relevant_data).strip()\n",
        "    #Create langChain Document with metadata\n",
        "    cleaned_documents.append(\n",
        "        Document(\n",
        "            page_content=formatted_text,\n",
        "            metadata={\n",
        "                \"brand\": relevant_data.get(\"brand\"),\n",
        "                \"category\": relevant_data.get(\"main_category\"),\n",
        "                \"price\": relevant_data.get(\"price\"),\n",
        "                \"rating\": relevant_data.get(\"average_rating\"),\n",
        "                \"verified_purchase\": relevant_data.get(\"verified_purchase\", False)\n",
        "            }\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "44gGqtGJ1xzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preview Sample"
      ],
      "metadata": {
        "id": "CJAbz1Ru2GLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_documents[0].page_content[:300])  # first 300 chars of first product\n",
        "print(cleaned_documents[0].metadata)\n"
      ],
      "metadata": {
        "id": "xTZJBh6P2KDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "page_content → what your RAG system searches and embeds for semantic similarity.\n",
        "\n",
        "metadata → optional filters and context, not embedded, but very helpful for precise results."
      ],
      "metadata": {
        "id": "t-VgIJEV5Irv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding"
      ],
      "metadata": {
        "id": "_Cdh3mxr26Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "1gXuT8zT64BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initailize embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "wI4OehbF7DZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FAISS Setup"
      ],
      "metadata": {
        "id": "PSW98Tgq8jjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create FAISS vector\n",
        "vectorstore = FAISS.from_documents(cleaned_documents, embeddings)"
      ],
      "metadata": {
        "id": "LwyjFCMR7PMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def faiss_search(query, top_k=3):\n",
        "    results = vectorstore.similarity_search_with_score(query, k=top_k)\n",
        "    return results"
      ],
      "metadata": {
        "id": "QKNMvcw08rL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BM25 Setup"
      ],
      "metadata": {
        "id": "1WiRqEoE8sN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "jkUuiVMc8u0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the cleaned documents for BM25\n",
        "corpus = [doc.page_content for doc in cleaned_documents]\n",
        "tokenized_corpus = [doc.split() for doc in corpus]\n",
        "\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "metadata": {
        "id": "tVZPHaw0-yx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_search(query, top_k=3):\n",
        "    tokenized_query = query.split()\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    top_indices = scores.argsort()[-top_k:][::-1]\n",
        "    results = [(cleaned_documents[i], scores[i]) for i in top_indices]\n",
        "    return results"
      ],
      "metadata": {
        "id": "pOcW4dqqAZ5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hybrid Search"
      ],
      "metadata": {
        "id": "7lXTeZ_bAdWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def hybrid_search(query, top_k=3, alpha=0.5):\n",
        "    # BM25 scores\n",
        "    tokenized_query = query.split()\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    bm25_norm = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + 1e-6)\n",
        "\n",
        "    # FAISS scores\n",
        "    faiss_results = vectorstore.similarity_search_with_score(query, k=len(cleaned_documents))\n",
        "\n",
        "    # Combine scores\n",
        "    combined_scores = []\n",
        "    for i, doc in enumerate(cleaned_documents):\n",
        "        faiss_score = next((score for d, score in faiss_results if d == doc), 0)\n",
        "        combined_score = alpha * bm25_norm[i] + (1 - alpha) * faiss_score\n",
        "        combined_scores.append((doc, combined_score))\n",
        "\n",
        "    # Sort top results\n",
        "    combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return combined_scores[:top_k]\n"
      ],
      "metadata": {
        "id": "rDkxA99tA-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Alpha controls weight:\n",
        "\n",
        "alpha=0.5 → BM25 and FAISS equally weighted\n",
        "\n",
        "alpha>0.5 → more weight on keyword matching\n",
        "\n",
        "alpha<0.5 → more weight on semantic search"
      ],
      "metadata": {
        "id": "xpfNTu8VDauL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compare Outputs"
      ],
      "metadata": {
        "id": "wUaOe_EyBa2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"wireless printer with connectivity issues\"\n",
        "top_k = 3\n",
        "\n",
        "print(\"=== BM25 Only ===\")\n",
        "for doc, score in bm25_search(query, top_k):\n",
        "    print(doc.page_content[:300])\n",
        "    print(doc.metadata)\n",
        "    print(\"Score:\", score)\n",
        "    print(\"-\"*80)\n",
        "\n",
        "print(\"=== FAISS Only ===\")\n",
        "for doc, score in faiss_search(query, top_k):\n",
        "    print(doc.page_content[:300])\n",
        "    print(doc.metadata)\n",
        "    print(\"Score:\", score)\n",
        "    print(\"-\"*80)\n",
        "\n",
        "# print(\"=== Hybrid ===\")\n",
        "# for doc, score in hybrid_search(query, top_k):\n",
        "#     print(doc.page_content[:300])\n",
        "#     print(doc.metadata)\n",
        "#     print(\"Score:\", score)\n",
        "#     print(\"-\"*80)\n"
      ],
      "metadata": {
        "id": "qLZO4jjBBaf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BM25-only → captures exact keyword matches; may miss semantically relevant products if phrasing differs.\n",
        "\n",
        "FAISS-only → finds products semantically similar, including those with synonyms or descriptive reviews.\n",
        "\n",
        "Hybrid → balances both; often retrieves the most relevant and precise results."
      ],
      "metadata": {
        "id": "1ozLXE7YB1DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_results = bm25_search(query, top_k)\n",
        "faiss_results = faiss_search(query, top_k)\n",
        "#hybrid_results = hybrid_search(query, top_k)\n"
      ],
      "metadata": {
        "id": "RaANAkKKCUzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for comparison\n",
        "table_data = []\n",
        "\n",
        "for i in range(top_k):\n",
        "    table_data.append({\n",
        "        \"Rank\": i+1,\n",
        "        \"BM25 Score\": round(bm25_results[i][1], 3),\n",
        "        \"FAISS Score\": round(faiss_results[i][1], 3),\n",
        "        \"Hybrid Score\": round(hybrid_results[i][1], 3),\n",
        "        \"BM25 Product\": bm25_results[i][0].page_content[:50] + \"...\",\n",
        "        \"FAISS Product\": faiss_results[i][0].page_content[:50] + \"...\",\n",
        "        \"Hybrid Product\": hybrid_results[i][0].page_content[:50] + \"...\",\n",
        "        \"BM25 Brand\": bm25_results[i][0].metadata.get(\"brand\"),\n",
        "        \"FAISS Brand\": faiss_results[i][0].metadata.get(\"brand\"),\n",
        "        \"Hybrid Brand\": hybrid_results[i][0].metadata.get(\"brand\")\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(table_data)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "GgqDNCTZCotS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "labels = [f\"Rank {i+1}\" for i in range(top_k)]\n",
        "x = np.arange(top_k)\n",
        "width = 0.25\n",
        "\n",
        "bm25_scores = [row['BM25 Score'] for row in table_data]\n",
        "faiss_scores = [row['FAISS Score'] for row in table_data]\n",
        "hybrid_scores = [row['Hybrid Score'] for row in table_data]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "\n",
        "ax.bar(x - width, bm25_scores, width, label='BM25')\n",
        "ax.bar(x, faiss_scores, width, label='FAISS')\n",
        "ax.bar(x + width, hybrid_scores, width, label='Hybrid')\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title(f'Top-{top_k} Retrieval Comparison for Query: \"{query}\"')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ymuHS0XvCrNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integrating RAG pipeline with Language Model"
      ],
      "metadata": {
        "id": "Vf9EiHqvEvTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "#Initialize LM\n",
        "#llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5) --Requires OpenAPI key"
      ],
      "metadata": {
        "id": "A1v395l6E05b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ubXqxO2CFnct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "##model_name = \"TheBloke/guanaco-7B-HF\"  # small model, GPU recommended. --crashed\n",
        "# model_name =\"TheBloke/guanaco-1.3B-HF\" --require authentication\n",
        "#model_name = \"tiiuae/falcon-7b\" --crashed\n",
        "# model_name = \"mosaicml/mpt-3b-storywriter\"  # 3B model\n",
        "#model_name = \"EleutherAI/gpt-neo-1.3B\" --- issue hallucinating\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#                     model_name,\n",
        "#                     device_map=\"auto\",        # automatically uses GPU if available\n",
        "#                     torch_dtype=torch.float16, # save VRAM\n",
        "#                     trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UcCm465BG0-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_pipeline = pipeline(\n",
        "    \"text2text-generation\", # FLAN-T5 uses text2text\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=500,  # only limits generated tokens, not input\n",
        "    temperature=0.7,\n",
        "    do_sample=False\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=local_pipeline)"
      ],
      "metadata": {
        "id": "_8AByqLoTp6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarizer pipeline\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=70,   # output summary length\n",
        "    min_length=20,\n",
        "    do_sample=False\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "nlbsmFbOVzgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Prompt Template\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template =  \"\"\"\n",
        "You are a Product Insights Assistant.\n",
        "\n",
        "Based on the following summarized past product data:\n",
        "\n",
        "{retrieved_docs}\n",
        "\n",
        "A new product has these details:\n",
        "{query}\n",
        "\n",
        "Provide **only** the insights in the format below. Do NOT include explanations or instructions:\n",
        "\n",
        "1. Expected average rating (number)\n",
        "2. Potential risks (brief list)\n",
        "3. Factors influencing performance (brief list)\n",
        "4. Specifications (brief list)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"retrieved_docs\", \"query\"],\n",
        "    template=prompt_template\n",
        ")\n"
      ],
      "metadata": {
        "id": "zm7Y7Mg_HCT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_product_insights_local(user_query, top_k=5, retriever=hybrid_search):\n",
        "    # Retrieve top-k relevant documents\n",
        "    top_docs = retriever(user_query, top_k=top_k)\n",
        "\n",
        "    #Summarize each document to keep input concise\n",
        "\n",
        "    summaries = []\n",
        "    for doc, score in top_docs[:5]:\n",
        "        summary = summarizer(doc.page_content, truncation=True)[0]['summary_text']\n",
        "        print(summary)\n",
        "        summaries.append(summary)\n",
        "\n",
        "    retrieved_text = \"\\n\".join(summaries)\n",
        "\n",
        "    # retrieved_text = \"\\n\\n\".join([doc.page_content for doc, score in top_docs[:3]]) -- too long input\n",
        "\n",
        "    # Format prompt\n",
        "    formatted_prompt = prompt.format(retrieved_docs=retrieved_text, query=user_query)\n",
        "    print(\"Output\")\n",
        "\n",
        "    # Generate insights\n",
        "    return llm(formatted_prompt, max_new_tokens=200)\n"
      ],
      "metadata": {
        "id": "wwv89nJwHM1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"New wireless printer for small business with low cost\"\n",
        "insights = generate_product_insights_local(query,5,bm25_search)\n",
        "print(insights)\n"
      ],
      "metadata": {
        "id": "DOboeoHjIF6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradio Setup"
      ],
      "metadata": {
        "id": "XN5kR-64PZll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_generate_insights(user_query, top_k, retriever_choice):\n",
        "    # Choose retriever\n",
        "    if retriever_choice == \"BM25\":\n",
        "        retriever = bm25_search\n",
        "    elif retriever_choice == \"FAISS\":\n",
        "        retriever = faiss_search\n",
        "    else:\n",
        "        retriever = hybrid_search\n",
        "\n",
        "    # Generate insights\n",
        "    insights = generate_product_insights_local(user_query, top_k=top_k, retriever=retriever)\n",
        "    return insights\n"
      ],
      "metadata": {
        "id": "XnaIVxY3PbTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_generate_insights,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2, placeholder=\"Enter new product details here...\", label=\"Product Query\"),\n",
        "        gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Top-K Documents\"),\n",
        "        gr.Radio(choices=[\"BM25\", \"FAISS\", \"Hybrid\"], value=\"Hybrid\", label=\"Retriever\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Product Insights\"),\n",
        "    title=\"Product Insights Assistant\",\n",
        "    description=\"Enter details of a new product and get expected ratings, risks, and performance insights using hybrid retrieval and local LLM.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "3KjgMpPhPeqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}